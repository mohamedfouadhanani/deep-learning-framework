{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dl import Model\n",
    "from dl import Dense\n",
    "from dl.activations import TanH, ReLU, LeakyReLU\n",
    "from dl.losses import MAE, MSE\n",
    "from dl.regularization import Dropout\n",
    "from dl.optimizers import AdaptiveMomentEstimation, MomentumGradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = 2000, 10\n",
    "inputs = np.random.randn(m, n)\n",
    "outputs = 2 * inputs + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10) (1600, 10)\n",
      "(80, 10) (80, 10)\n",
      "(320, 10) (320, 10)\n"
     ]
    }
   ],
   "source": [
    "# train, val, test split\n",
    "def train_test_split(inputs, outputs, pourcentage):\n",
    "    m, _ = inputs.shape\n",
    "    permutation = np.random.permutation(m)\n",
    "    m_train = np.ceil(m * pourcentage).astype(int)\n",
    "\n",
    "    inputs_train = inputs[permutation[:m_train]]\n",
    "    inputs_test = inputs[permutation[m_train:]]\n",
    "\n",
    "    outputs_train = outputs[permutation[:m_train]]\n",
    "    outputs_test = outputs[permutation[m_train:]]\n",
    "\n",
    "    return inputs_train, outputs_train, inputs_test, outputs_test\n",
    "\n",
    "inputs_train, outputs_train, inputs_test, outputs_test = train_test_split(inputs, outputs, pourcentage=0.8)\n",
    "inputs_val, outputs_val, inputs_test, outputs_test = train_test_split(inputs_test, outputs_test, pourcentage=0.8)\n",
    "\n",
    "print(inputs_train.shape, outputs_train.shape)\n",
    "print(inputs_test.shape, outputs_test.shape)\n",
    "print(inputs_val.shape, outputs_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([\n",
    "    Dense(n, 32),\n",
    "    ReLU(),\n",
    "    Dropout(keep_prob=0.6),\n",
    "    Dense(32, 5),\n",
    "    ReLU(),\n",
    "    Dropout(keep_prob=0.8),\n",
    "    Dense(5, 32),\n",
    "    LeakyReLU(0.3),\n",
    "    Dropout(keep_prob=0.4),\n",
    "    Dense(32, n)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSE()\n",
    "# loss = MAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdaptiveMomentEstimation(learning_rate, batch_size, beta1, beta2)\n",
    "# optimizer = MomentumGradientDescent(learning_rate, batch_size, beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/500]: loss = 26063.904063288323\n",
      "[2/500]: loss = 2716.4197025212534\n",
      "[3/500]: loss = 436.6937085761498\n",
      "[4/500]: loss = 176.74825967282584\n",
      "[5/500]: loss = 122.78082854429222\n",
      "[6/500]: loss = 98.54273007109929\n",
      "[7/500]: loss = 84.54565983985952\n",
      "[8/500]: loss = 76.39470386375854\n",
      "[9/500]: loss = 66.83841632026976\n",
      "[10/500]: loss = 58.59498237676705\n",
      "[11/500]: loss = 53.70006453769306\n",
      "[12/500]: loss = 50.62405381335565\n",
      "[13/500]: loss = 43.449607585778615\n",
      "[14/500]: loss = 35.25583112318268\n",
      "[15/500]: loss = 31.551700246178303\n",
      "[16/500]: loss = 29.298335710837033\n",
      "[17/500]: loss = 26.03061012488138\n",
      "[18/500]: loss = 24.42536368060509\n",
      "[19/500]: loss = 22.30038081837516\n",
      "[20/500]: loss = 19.71577160800259\n",
      "[21/500]: loss = 16.140563753590868\n",
      "[22/500]: loss = 15.01841725383492\n",
      "[23/500]: loss = 13.682767732091827\n",
      "[24/500]: loss = 12.489440361667029\n",
      "[25/500]: loss = 11.271180733567617\n",
      "[26/500]: loss = 10.277731715178142\n",
      "[27/500]: loss = 9.247722750320525\n",
      "[28/500]: loss = 8.517366433870171\n",
      "[29/500]: loss = 7.1838891066041\n",
      "[30/500]: loss = 7.322819839938984\n",
      "[31/500]: loss = 6.239902023031757\n",
      "[32/500]: loss = 6.166128389474463\n",
      "[33/500]: loss = 5.381759975870746\n",
      "[34/500]: loss = 4.74974665817658\n",
      "[35/500]: loss = 4.497478702625235\n",
      "[36/500]: loss = 3.9281398060210773\n",
      "[37/500]: loss = 3.5885465980921167\n",
      "[38/500]: loss = 3.5447047134065746\n",
      "[39/500]: loss = 3.2640434871837734\n",
      "[40/500]: loss = 2.951115455766737\n",
      "[41/500]: loss = 2.7601280762992166\n",
      "[42/500]: loss = 2.765922451562779\n",
      "[43/500]: loss = 2.5388916987007084\n",
      "[44/500]: loss = 2.3573761134457527\n",
      "[45/500]: loss = 2.125914547017957\n",
      "[46/500]: loss = 2.035741086604092\n",
      "[47/500]: loss = 1.9851071265069202\n",
      "[48/500]: loss = 1.8300358969112167\n",
      "[49/500]: loss = 1.6195587550253812\n",
      "[50/500]: loss = 1.5795803830173665\n",
      "[51/500]: loss = 1.6555561583786602\n",
      "[52/500]: loss = 1.4466528149742066\n",
      "[53/500]: loss = 1.4243575945265363\n",
      "[54/500]: loss = 1.2705201135925608\n",
      "[55/500]: loss = 1.255539362925018\n",
      "[56/500]: loss = 1.1861104804942342\n",
      "[57/500]: loss = 1.1331988196798641\n",
      "[58/500]: loss = 1.0711863955841112\n",
      "[59/500]: loss = 1.0778373395211551\n",
      "[60/500]: loss = 0.957138234925724\n",
      "[61/500]: loss = 0.9017800632624257\n",
      "[62/500]: loss = 0.8437483439714103\n",
      "[63/500]: loss = 0.8504190854568477\n",
      "[64/500]: loss = 0.8486091731954243\n",
      "[65/500]: loss = 0.7534057620144428\n",
      "[66/500]: loss = 0.7493738525959978\n",
      "[67/500]: loss = 0.6946218280336478\n",
      "[68/500]: loss = 0.6903795152584654\n",
      "[69/500]: loss = 0.6520718859788598\n",
      "[70/500]: loss = 0.6286052333913026\n",
      "[71/500]: loss = 0.5814313896731329\n",
      "[72/500]: loss = 0.5847077512642038\n",
      "[73/500]: loss = 0.5585120005931581\n",
      "[74/500]: loss = 0.5132720684906619\n",
      "[75/500]: loss = 0.5002485602054156\n",
      "[76/500]: loss = 0.4924272630115173\n",
      "[77/500]: loss = 0.44407349760864284\n",
      "[78/500]: loss = 0.43163492709807555\n",
      "[79/500]: loss = 0.42017035148379933\n",
      "[80/500]: loss = 0.4037227022520378\n",
      "[81/500]: loss = 0.3721969138557619\n",
      "[82/500]: loss = 0.35970500152860635\n",
      "[83/500]: loss = 0.3528035828468334\n",
      "[84/500]: loss = 0.33242062228500585\n",
      "[85/500]: loss = 0.32517502810099086\n",
      "[86/500]: loss = 0.31764715761529666\n",
      "[87/500]: loss = 0.3019689402023966\n",
      "[88/500]: loss = 0.2836335029282506\n",
      "[89/500]: loss = 0.274719572480683\n",
      "[90/500]: loss = 0.27449966006363213\n",
      "[91/500]: loss = 0.266634024065755\n",
      "[92/500]: loss = 0.258469120481948\n",
      "[93/500]: loss = 0.24555197655726752\n",
      "[94/500]: loss = 0.23595978129207962\n",
      "[95/500]: loss = 0.23502796567440382\n",
      "[96/500]: loss = 0.23135297837088523\n",
      "[97/500]: loss = 0.22766706612858342\n",
      "[98/500]: loss = 0.21760654726723724\n",
      "[99/500]: loss = 0.21294301160875542\n",
      "[100/500]: loss = 0.2101071918200664\n",
      "[101/500]: loss = 0.2074087734759773\n",
      "[102/500]: loss = 0.19997042218014008\n",
      "[103/500]: loss = 0.200776452003177\n",
      "[104/500]: loss = 0.19514888404724445\n",
      "[105/500]: loss = 0.195382530461378\n",
      "[106/500]: loss = 0.1908035625062675\n",
      "[107/500]: loss = 0.188208773242856\n",
      "[108/500]: loss = 0.1882019306343592\n",
      "[109/500]: loss = 0.1873899695994269\n",
      "[110/500]: loss = 0.18600337736962996\n",
      "[111/500]: loss = 0.18125158755840015\n",
      "[112/500]: loss = 0.1800193541149241\n",
      "[113/500]: loss = 0.17631844807595567\n",
      "[114/500]: loss = 0.1771626797908748\n",
      "[115/500]: loss = 0.17775355823115446\n",
      "[116/500]: loss = 0.1737452049698065\n",
      "[117/500]: loss = 0.17309770208246028\n",
      "[118/500]: loss = 0.17346079980459136\n",
      "[119/500]: loss = 0.17222871080039706\n",
      "[120/500]: loss = 0.17032130489618907\n",
      "[121/500]: loss = 0.17066455161714955\n",
      "[122/500]: loss = 0.1713678037422952\n",
      "[123/500]: loss = 0.17008368718787245\n",
      "[124/500]: loss = 0.1700094389930041\n",
      "[125/500]: loss = 0.1698350560562202\n",
      "[126/500]: loss = 0.16782673465738307\n",
      "[127/500]: loss = 0.16720871222163097\n",
      "[128/500]: loss = 0.1668842519072092\n",
      "[129/500]: loss = 0.16630222526587563\n",
      "[130/500]: loss = 0.1647612361348422\n",
      "[131/500]: loss = 0.1659470424313575\n",
      "[132/500]: loss = 0.1656392170173443\n",
      "[133/500]: loss = 0.16350918063313977\n",
      "[134/500]: loss = 0.1639263099887996\n",
      "[135/500]: loss = 0.16336410282937502\n",
      "[136/500]: loss = 0.16395365113129184\n",
      "[137/500]: loss = 0.16255857117129793\n",
      "[138/500]: loss = 0.16085823374128982\n",
      "[139/500]: loss = 0.1611908151621369\n",
      "[140/500]: loss = 0.16008971102580624\n",
      "[141/500]: loss = 0.1601453198102136\n",
      "[142/500]: loss = 0.15947124202853263\n",
      "[143/500]: loss = 0.15946871137876348\n",
      "[144/500]: loss = 0.15854835754405053\n",
      "[145/500]: loss = 0.15920721002812835\n",
      "[146/500]: loss = 0.1584083566200885\n",
      "[147/500]: loss = 0.1579822073297089\n",
      "[148/500]: loss = 0.1575958728296668\n",
      "[149/500]: loss = 0.15620775207988927\n",
      "[150/500]: loss = 0.15569340755891856\n",
      "[151/500]: loss = 0.15492811690288635\n",
      "[152/500]: loss = 0.15423099412735605\n",
      "[153/500]: loss = 0.1535061505490238\n",
      "[154/500]: loss = 0.15351669995277997\n",
      "[155/500]: loss = 0.15249898569515466\n",
      "[156/500]: loss = 0.15238199837783434\n",
      "[157/500]: loss = 0.1526035156635858\n",
      "[158/500]: loss = 0.1516923653787755\n",
      "[159/500]: loss = 0.14889939018027637\n",
      "[160/500]: loss = 0.15004728588660118\n",
      "[161/500]: loss = 0.1497582037289107\n",
      "[162/500]: loss = 0.1482650615172618\n",
      "[163/500]: loss = 0.14820976219269286\n",
      "[164/500]: loss = 0.14638519771789793\n",
      "[165/500]: loss = 0.1470181765208574\n",
      "[166/500]: loss = 0.1456379437296325\n",
      "[167/500]: loss = 0.14556791424384355\n",
      "[168/500]: loss = 0.14426299910218005\n",
      "[169/500]: loss = 0.1445306415623605\n",
      "[170/500]: loss = 0.14366122245429278\n",
      "[171/500]: loss = 0.14386150108688492\n",
      "[172/500]: loss = 0.14242560060793638\n",
      "[173/500]: loss = 0.14268245303534835\n",
      "[174/500]: loss = 0.14153234383912677\n",
      "[175/500]: loss = 0.14114386132105652\n",
      "[176/500]: loss = 0.13939330777562436\n",
      "[177/500]: loss = 0.14067053231162943\n",
      "[178/500]: loss = 0.14062670526637255\n",
      "[179/500]: loss = 0.1404336848238253\n",
      "[180/500]: loss = 0.13961729411305626\n",
      "[181/500]: loss = 0.13910008434817692\n",
      "[182/500]: loss = 0.13773784083216742\n",
      "[183/500]: loss = 0.13877298097681803\n",
      "[184/500]: loss = 0.13849958319579245\n",
      "[185/500]: loss = 0.13823295847394246\n",
      "[186/500]: loss = 0.13772104556302153\n",
      "[187/500]: loss = 0.13758344342168202\n",
      "[188/500]: loss = 0.13698312777112823\n",
      "[189/500]: loss = 0.1373717263263331\n",
      "[190/500]: loss = 0.13647248676955956\n",
      "[191/500]: loss = 0.13706645874069462\n",
      "[192/500]: loss = 0.1367602079009411\n",
      "[193/500]: loss = 0.1362232510312159\n",
      "[194/500]: loss = 0.13650552375426753\n",
      "[195/500]: loss = 0.13646240373864157\n",
      "[196/500]: loss = 0.13517843350571632\n",
      "[197/500]: loss = 0.13593620592538985\n",
      "[198/500]: loss = 0.13683106852486884\n",
      "[199/500]: loss = 0.13512384228656757\n",
      "[200/500]: loss = 0.135159499888914\n",
      "[201/500]: loss = 0.1340282835304248\n",
      "[202/500]: loss = 0.13335873313398963\n",
      "[203/500]: loss = 0.13390243828259904\n",
      "[204/500]: loss = 0.13370551759680624\n",
      "[205/500]: loss = 0.13342792408006598\n",
      "[206/500]: loss = 0.13333184732692394\n",
      "[207/500]: loss = 0.13352988307060754\n",
      "[208/500]: loss = 0.13358915524264206\n",
      "[209/500]: loss = 0.13324788106174718\n",
      "[210/500]: loss = 0.13202382396514406\n",
      "[211/500]: loss = 0.13245547083679016\n",
      "[212/500]: loss = 0.13272054148821988\n",
      "[213/500]: loss = 0.13176882026557982\n",
      "[214/500]: loss = 0.13226713179017724\n",
      "[215/500]: loss = 0.13208063000116252\n",
      "[216/500]: loss = 0.13309499097194377\n",
      "[217/500]: loss = 0.13299569597823313\n",
      "[218/500]: loss = 0.13107688703272807\n",
      "[219/500]: loss = 0.1318991341539471\n",
      "[220/500]: loss = 0.13157826258082472\n",
      "[221/500]: loss = 0.13227365838946387\n",
      "[222/500]: loss = 0.13182623204583335\n",
      "[223/500]: loss = 0.1306152038537219\n",
      "[224/500]: loss = 0.13152015360280295\n",
      "[225/500]: loss = 0.1306106801948567\n",
      "[226/500]: loss = 0.1290578534620957\n",
      "[227/500]: loss = 0.13039503805964014\n",
      "[228/500]: loss = 0.1300702408017916\n",
      "[229/500]: loss = 0.1302297616988861\n",
      "[230/500]: loss = 0.12995701674767535\n",
      "[231/500]: loss = 0.13025214021344397\n",
      "[232/500]: loss = 0.13019246175176724\n",
      "[233/500]: loss = 0.13015389107815742\n",
      "[234/500]: loss = 0.12882697559037853\n",
      "[235/500]: loss = 0.12994469981433757\n",
      "[236/500]: loss = 0.12969386375113548\n",
      "[237/500]: loss = 0.1306524300097803\n",
      "[238/500]: loss = 0.13062690995137508\n",
      "[239/500]: loss = 0.12931148493215786\n",
      "[240/500]: loss = 0.12967554031276626\n",
      "[241/500]: loss = 0.13052227579050876\n",
      "[242/500]: loss = 0.12929233226545508\n",
      "[243/500]: loss = 0.1293855187547643\n",
      "[244/500]: loss = 0.12942469310949484\n",
      "[245/500]: loss = 0.1290079760724865\n",
      "[246/500]: loss = 0.12915815509361037\n",
      "[247/500]: loss = 0.12998018859552557\n",
      "[248/500]: loss = 0.13018575837860635\n",
      "[249/500]: loss = 0.1295073283237235\n",
      "[250/500]: loss = 0.1283308732283421\n",
      "[251/500]: loss = 0.12945699228077395\n",
      "[252/500]: loss = 0.12946509526983369\n",
      "[253/500]: loss = 0.12747254545239392\n",
      "[254/500]: loss = 0.12830492146503047\n",
      "[255/500]: loss = 0.12910314676124796\n",
      "[256/500]: loss = 0.12757186815238505\n",
      "[257/500]: loss = 0.1283322293435099\n",
      "[258/500]: loss = 0.1291382445652811\n",
      "[259/500]: loss = 0.12943364041963673\n",
      "[260/500]: loss = 0.1277178684173812\n",
      "[261/500]: loss = 0.12884230568384297\n",
      "[262/500]: loss = 0.12895464695988543\n",
      "[263/500]: loss = 0.130015763511438\n",
      "[264/500]: loss = 0.12860778992675134\n",
      "[265/500]: loss = 0.1282016488495661\n",
      "[266/500]: loss = 0.12874532423589452\n",
      "[267/500]: loss = 0.12859711386258296\n",
      "[268/500]: loss = 0.1290329700410249\n",
      "[269/500]: loss = 0.1289723403075952\n",
      "[270/500]: loss = 0.12741111792522594\n",
      "[271/500]: loss = 0.12847495677399948\n",
      "[272/500]: loss = 0.12963945634361843\n",
      "[273/500]: loss = 0.12925053666659592\n",
      "[274/500]: loss = 0.12848405388069914\n",
      "[275/500]: loss = 0.12841066464732795\n",
      "[276/500]: loss = 0.12882074619449393\n",
      "[277/500]: loss = 0.12845454663184463\n",
      "[278/500]: loss = 0.12852569984562587\n",
      "[279/500]: loss = 0.1291697163507557\n",
      "[280/500]: loss = 0.12825478024585818\n",
      "[281/500]: loss = 0.12873524594028118\n",
      "[282/500]: loss = 0.12779410729122542\n",
      "[283/500]: loss = 0.1276497475688665\n",
      "[284/500]: loss = 0.1281425966218724\n",
      "[285/500]: loss = 0.12943314454958962\n",
      "[286/500]: loss = 0.1286420330822356\n",
      "[287/500]: loss = 0.12885695317996126\n",
      "[288/500]: loss = 0.1281729503129319\n",
      "[289/500]: loss = 0.12811286468295216\n",
      "[290/500]: loss = 0.12703654074861315\n",
      "[291/500]: loss = 0.12679243964328243\n",
      "[292/500]: loss = 0.12799309161216077\n",
      "[293/500]: loss = 0.1283364332399909\n",
      "[294/500]: loss = 0.12784724677308476\n",
      "[295/500]: loss = 0.12809885520800365\n",
      "[296/500]: loss = 0.12809282228841334\n",
      "[297/500]: loss = 0.12941639913622477\n",
      "[298/500]: loss = 0.12955877261315737\n",
      "[299/500]: loss = 0.12857624335338963\n",
      "[300/500]: loss = 0.1274316920586685\n",
      "[301/500]: loss = 0.12812814009070586\n",
      "[302/500]: loss = 0.12810152939403505\n",
      "[303/500]: loss = 0.12821624031777776\n",
      "[304/500]: loss = 0.12854477896351457\n",
      "[305/500]: loss = 0.12902477419641145\n",
      "[306/500]: loss = 0.1283484287587509\n",
      "[307/500]: loss = 0.1288648927899859\n",
      "[308/500]: loss = 0.12799251876432946\n",
      "[309/500]: loss = 0.12893713522782485\n",
      "[310/500]: loss = 0.12834759441870733\n",
      "[311/500]: loss = 0.12759693986173504\n",
      "[312/500]: loss = 0.12858132751589754\n",
      "[313/500]: loss = 0.12781711467895357\n",
      "[314/500]: loss = 0.12745776919575114\n",
      "[315/500]: loss = 0.12699695352988397\n",
      "[316/500]: loss = 0.12690999037917505\n",
      "[317/500]: loss = 0.12839911956138933\n",
      "[318/500]: loss = 0.12800338683781853\n",
      "[319/500]: loss = 0.12905627510791026\n",
      "[320/500]: loss = 0.1290449463301409\n",
      "[321/500]: loss = 0.12763701190513965\n",
      "[322/500]: loss = 0.12916425931442957\n",
      "[323/500]: loss = 0.128046357207384\n",
      "[324/500]: loss = 0.12844996039816212\n",
      "[325/500]: loss = 0.12670604548895747\n",
      "[326/500]: loss = 0.1276757158155282\n",
      "[327/500]: loss = 0.12697142993452817\n",
      "[328/500]: loss = 0.12675216671076592\n",
      "[329/500]: loss = 0.12808737613636365\n",
      "[330/500]: loss = 0.12920521644244543\n",
      "[331/500]: loss = 0.12744540154623854\n",
      "[332/500]: loss = 0.12809278468016352\n",
      "[333/500]: loss = 0.1279162075961056\n",
      "[334/500]: loss = 0.12675064416757176\n",
      "[335/500]: loss = 0.12895894185314455\n",
      "[336/500]: loss = 0.1276134946979023\n",
      "[337/500]: loss = 0.12673113041020187\n",
      "[338/500]: loss = 0.1272849059897245\n",
      "[339/500]: loss = 0.12765189417619902\n",
      "[340/500]: loss = 0.12912727453588102\n",
      "[341/500]: loss = 0.12931839581189342\n",
      "[342/500]: loss = 0.12659579848539765\n",
      "[343/500]: loss = 0.12786507922473447\n",
      "[344/500]: loss = 0.1279878489915338\n",
      "[345/500]: loss = 0.12673726604207813\n",
      "[346/500]: loss = 0.12817176604448197\n",
      "[347/500]: loss = 0.12817074562386443\n",
      "[348/500]: loss = 0.12702693984855654\n",
      "[349/500]: loss = 0.12814305558100095\n",
      "[350/500]: loss = 0.1269223746381423\n",
      "[351/500]: loss = 0.12772946333962598\n",
      "[352/500]: loss = 0.1283428873938298\n",
      "[353/500]: loss = 0.12711442049567107\n",
      "[354/500]: loss = 0.12766158578841627\n",
      "[355/500]: loss = 0.12727975879323666\n",
      "[356/500]: loss = 0.12801178511237585\n",
      "[357/500]: loss = 0.12773712609373197\n",
      "[358/500]: loss = 0.1276268103243574\n",
      "[359/500]: loss = 0.12773070562441324\n",
      "[360/500]: loss = 0.12764555468951497\n",
      "[361/500]: loss = 0.1289440893041849\n",
      "[362/500]: loss = 0.12773213894763097\n",
      "[363/500]: loss = 0.12796451898277744\n",
      "[364/500]: loss = 0.12791971783607556\n",
      "[365/500]: loss = 0.12761568170865442\n",
      "[366/500]: loss = 0.12793963006966946\n",
      "[367/500]: loss = 0.1289380921157603\n",
      "[368/500]: loss = 0.12877305758508703\n",
      "[369/500]: loss = 0.12768804157435792\n",
      "[370/500]: loss = 0.1279351351484034\n",
      "[371/500]: loss = 0.1277498155030807\n",
      "[372/500]: loss = 0.12772138878341982\n",
      "[373/500]: loss = 0.12768139529438421\n",
      "[374/500]: loss = 0.12776924850658988\n",
      "[375/500]: loss = 0.12791264136345112\n",
      "[376/500]: loss = 0.12895012444281737\n",
      "[377/500]: loss = 0.12788812358329724\n",
      "[378/500]: loss = 0.1281354372746788\n",
      "[379/500]: loss = 0.1291364142247071\n",
      "[380/500]: loss = 0.12764145215788955\n",
      "[381/500]: loss = 0.12793516508634653\n",
      "[382/500]: loss = 0.1278305746514285\n",
      "[383/500]: loss = 0.1276281794402477\n",
      "[384/500]: loss = 0.127305229415796\n",
      "[385/500]: loss = 0.12738829464455195\n",
      "[386/500]: loss = 0.1280633993768567\n",
      "[387/500]: loss = 0.12764890545340712\n",
      "[388/500]: loss = 0.12624178845429385\n",
      "[389/500]: loss = 0.1283369749705352\n",
      "[390/500]: loss = 0.12795230306973054\n",
      "[391/500]: loss = 0.1277865924720391\n",
      "[392/500]: loss = 0.1270866075847884\n",
      "[393/500]: loss = 0.1282095212354917\n",
      "[394/500]: loss = 0.1276516646249034\n",
      "[395/500]: loss = 0.1286950006082556\n",
      "[396/500]: loss = 0.127889235035524\n",
      "[397/500]: loss = 0.12776070697409292\n",
      "[398/500]: loss = 0.12963382299351597\n",
      "[399/500]: loss = 0.12759671797814756\n",
      "[400/500]: loss = 0.12761818794927446\n",
      "[401/500]: loss = 0.12676303111853018\n",
      "[402/500]: loss = 0.1280805212657476\n",
      "[403/500]: loss = 0.12687203048144297\n",
      "[404/500]: loss = 0.12884306472161625\n",
      "[405/500]: loss = 0.12732287391107838\n",
      "[406/500]: loss = 0.12922225226337158\n",
      "[407/500]: loss = 0.12703374378073906\n",
      "[408/500]: loss = 0.12791377363982984\n",
      "[409/500]: loss = 0.12846487096499093\n",
      "[410/500]: loss = 0.1278836952424512\n",
      "[411/500]: loss = 0.1266161115937231\n",
      "[412/500]: loss = 0.12706178323707967\n",
      "[413/500]: loss = 0.1284825216559174\n",
      "[414/500]: loss = 0.12906197823175666\n",
      "[415/500]: loss = 0.12825577444084488\n",
      "[416/500]: loss = 0.12887998119221875\n",
      "[417/500]: loss = 0.12737879133910301\n",
      "[418/500]: loss = 0.12781358967084988\n",
      "[419/500]: loss = 0.1281572807424445\n",
      "[420/500]: loss = 0.12737584262223284\n",
      "[421/500]: loss = 0.12743505814094833\n",
      "[422/500]: loss = 0.12712182310108455\n",
      "[423/500]: loss = 0.12815230938514913\n",
      "[424/500]: loss = 0.1268023631586415\n",
      "[425/500]: loss = 0.12790807836243698\n",
      "[426/500]: loss = 0.1292747045818578\n",
      "[427/500]: loss = 0.12955089364524983\n",
      "[428/500]: loss = 0.12692525343547983\n",
      "[429/500]: loss = 0.12869943920226332\n",
      "[430/500]: loss = 0.1264903408482003\n",
      "[431/500]: loss = 0.12793975128522164\n",
      "[432/500]: loss = 0.1280772746642427\n",
      "[433/500]: loss = 0.12802298767415218\n",
      "[434/500]: loss = 0.12804509434095931\n",
      "[435/500]: loss = 0.12890026505006275\n",
      "[436/500]: loss = 0.12880784183903643\n",
      "[437/500]: loss = 0.12772440712923352\n",
      "[438/500]: loss = 0.12907069202797503\n",
      "[439/500]: loss = 0.1283133024568816\n",
      "[440/500]: loss = 0.1280189869935175\n",
      "[441/500]: loss = 0.1282766749141091\n",
      "[442/500]: loss = 0.12897135861097808\n",
      "[443/500]: loss = 0.1285418555895183\n",
      "[444/500]: loss = 0.12810073699681232\n",
      "[445/500]: loss = 0.12889405151122796\n",
      "[446/500]: loss = 0.12835620809190443\n",
      "[447/500]: loss = 0.12793423475944615\n",
      "[448/500]: loss = 0.12746381895119796\n",
      "[449/500]: loss = 0.12774386008168917\n",
      "[450/500]: loss = 0.12715250790336666\n",
      "[451/500]: loss = 0.12759514727092203\n",
      "[452/500]: loss = 0.12831464668463385\n",
      "[453/500]: loss = 0.1286981786499482\n",
      "[454/500]: loss = 0.12859792187327404\n",
      "[455/500]: loss = 0.12704693776819445\n",
      "[456/500]: loss = 0.12805313076509214\n",
      "[457/500]: loss = 0.1287104114149359\n",
      "[458/500]: loss = 0.12695938461677989\n",
      "[459/500]: loss = 0.12746999725822364\n",
      "[460/500]: loss = 0.12839893957109488\n",
      "[461/500]: loss = 0.12768454928456952\n",
      "[462/500]: loss = 0.12779371890402574\n",
      "[463/500]: loss = 0.1277296610963175\n",
      "[464/500]: loss = 0.12788192003778748\n",
      "[465/500]: loss = 0.12854273444078806\n",
      "[466/500]: loss = 0.12706094796445583\n",
      "[467/500]: loss = 0.12834803220960592\n",
      "[468/500]: loss = 0.1277229229223946\n",
      "[469/500]: loss = 0.12778174463539407\n",
      "[470/500]: loss = 0.12709989902876828\n",
      "[471/500]: loss = 0.1281608897881052\n",
      "[472/500]: loss = 0.1276676273049926\n",
      "[473/500]: loss = 0.12825728660760935\n",
      "[474/500]: loss = 0.1284513910973594\n",
      "[475/500]: loss = 0.12664624200735555\n",
      "[476/500]: loss = 0.12826242816697891\n",
      "[477/500]: loss = 0.12822733894799626\n",
      "[478/500]: loss = 0.12908153178913775\n",
      "[479/500]: loss = 0.12753638079010565\n",
      "[480/500]: loss = 0.12776038964488895\n",
      "[481/500]: loss = 0.12796597913366714\n",
      "[482/500]: loss = 0.12850673972065363\n",
      "[483/500]: loss = 0.1283095532059866\n",
      "[484/500]: loss = 0.1280211849667707\n",
      "[485/500]: loss = 0.12796739617121577\n",
      "[486/500]: loss = 0.12636587768442192\n",
      "[487/500]: loss = 0.1280419294954847\n",
      "[488/500]: loss = 0.12787883573411457\n",
      "[489/500]: loss = 0.12785828454732293\n",
      "[490/500]: loss = 0.12863383257146285\n",
      "[491/500]: loss = 0.126850624762557\n",
      "[492/500]: loss = 0.12821938049385997\n",
      "[493/500]: loss = 0.12705771360375778\n",
      "[494/500]: loss = 0.1276797985655356\n",
      "[495/500]: loss = 0.12776472561593458\n",
      "[496/500]: loss = 0.12813392813716623\n",
      "[497/500]: loss = 0.12802705261862862\n",
      "[498/500]: loss = 0.1268985175123807\n",
      "[499/500]: loss = 0.1278070632024738\n",
      "[500/500]: loss = 0.12716136809151707\n"
     ]
    }
   ],
   "source": [
    "history = model.optimize(inputs_train, outputs_train, n_epochs, verbose=True, inputs_val=inputs_val, outputs_val=outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(range(len(history[\"train_losses\"])))\n",
    "\n",
    "fig, axs = plt.subplots(2, sharex=True)\n",
    "fig.suptitle('Training & Validation Loss')\n",
    "\n",
    "axs[0].plot(X, history[\"train_losses\"])\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Training Loss\")\n",
    "\n",
    "axs[1].plot(X, history[\"val_losses\"])\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Validation Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.396101469510691\n"
     ]
    }
   ],
   "source": [
    "predictions = model(inputs_val, is_optimizing=False)\n",
    "l = loss.forward(predictions, outputs_val)\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.490783399175523\n"
     ]
    }
   ],
   "source": [
    "predictions = model(inputs_test, is_optimizing=False)\n",
    "l = loss.forward(predictions, outputs_test)\n",
    "\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ff79fb053fb88e18eab83b8116863beb7409b92540c23c781114755009620a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
